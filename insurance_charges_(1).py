# -*- coding: utf-8 -*-
"""insurance_charges (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2GJIpDRo3BIxllnic-fAKt90kTyS1ls
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn import metrics

# Veri dosyanızın yolunu belirtin
data_path = 'insurance.csv'

# Verileri okuyun
df = pd.read_csv(data_path)
# İlk beş satırı görüntüleyin
df.head(150)

df.info()

null_values = df.isnull().sum()
print(null_values)

df.describe()

print(df.columns)

insurance_data = pd.read_csv("insurance.csv")
print(insurance_data['sex'].value_counts())
print(insurance_data['smoker'].value_counts())
print(insurance_data['region'].value_counts())

insurance_data = pd.read_csv("insurance.csv")
age = insurance_data['age']
bmi = insurance_data['bmi']
children= insurance_data['children']
charges = insurance_data['charges']

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Veri setini oku
insurance_data = pd.read_csv("insurance.csv")

# Kategorik ve sayısal sütunları ayır
categorical_columns = ['sex', 'smoker', 'region']
numerical_columns = ['age', 'bmi', 'children', 'charges']

# Yeni bir figür oluştur
fig, axs = plt.subplots(len(categorical_columns), len(numerical_columns), figsize=(15,15))

# Figürün üst başlığını ayarla
fig.suptitle('Visualizing categorical data columns')

# Her kategorik sütun için
for i, cat_col in enumerate(categorical_columns):
    # Her sayısal sütun için
    for j, num_col in enumerate(numerical_columns):
        # Kategorik sütundaki her benzersiz değer için
        for val in insurance_data[cat_col].unique():
            # Benzersiz değere ait sayısal verileri al
            num_data = insurance_data[insurance_data[cat_col] == val][num_col]
            # Bir sütun grafiği çiz
            axs[i, j].bar([val], [np.mean(num_data)])
            axs[i, j].set_xlabel(cat_col)
            axs[i, j].set_ylabel('Average ' + num_col)

# Grafiği göster
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Stili ayarla
plt.style.use('ggplot')

# Yeni bir figür oluştur ve bu figürü 1 satır ve 4 sütunlu bir ızgara halinde böler
fig, axes = plt.subplots(1,4,figsize=(20,5))

# Figürün üst başlığını ayarla
fig.suptitle('Visualizing numerical columns')

# Yaşa göre sigorta ücretini gösteren bir çubuk grafiği çiz ve bu grafiği ilk alt grafiğe yerleştir
sns.barplot(x='age', y='charges', data=df, ax=axes[0])

# BMI'ya göre sigorta ücretini gösteren bir çubuk grafiği çiz ve bu grafiği ikinci alt grafiğe yerleştir
sns.barplot(x='bmi', y='charges', data=df, ax=axes[1])

# Çocuk sayısına göre sigorta ücretini gösteren bir çubuk grafiği çiz ve bu grafiği üçüncü alt grafiğe yerleştir
sns.barplot(x='children', y='charges', data=df, ax=axes[2])

# Sigorta ücretlerinin dağılımını gösteren bir histogram çiz ve bu grafiği dördüncü alt grafiğe yerleştir
sns.histplot(df['charges'], ax=axes[3])

# Grafiği göster
plt.show()

# Sayısal sütunların varyansını hesapla
variance = df[['age', 'bmi', 'children', 'charges']].var()

# Varyansı yazdır
print(variance)

selected_data = df[['age', 'bmi', 'children', 'charges']]
print(selected_data)

import seaborn as sns
import matplotlib.pyplot as plt

# Sayısal sütunları seçin
numeric_data = df[['age', 'bmi', 'children', 'charges']]

# Figürü oluşturun
plt.figure(figsize=(10,7))

# Isı haritasını çizin
sns.heatmap(numeric_data.corr(), annot=True)

# Başlığı ayarlayın
plt.title('Columns between the correlation')

# Gösterin
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler

# veri setinizi okuyun
df = pd.read_csv('insurance.csv')

# Kategorik değişkenleri sayısal hale getirin
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['smoker'] = le.fit_transform(df['smoker'])
df['region'] = le.fit_transform(df['region'])

# 'charges' değişkenini medyan değerine göre ikiye ayırın
median_charges = df['charges'].median()
df['charges'] = [1 if i > median_charges else 0 for i in df['charges']]

# Bağımlı ve bağımsız değişkenleri ayırın
X = df.drop('charges', axis=1)
y = df['charges']

# Veriyi eğitim ve test setlerine ayırın
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Özellikleri ölçeklendirin
scaler = StandardScaler()
X_train[['bmi', 'children']] = scaler.fit_transform(X_train[['bmi', 'children']])
X_test[['bmi', 'children']] = scaler.transform(X_test[['bmi', 'children']])

# Lojistik Regresyon modelini oluşturun ve eğitin
model = LogisticRegression()
model.fit(X_train, y_train)

# Modelin doğruluğunu kontrol edin
accuracy = model.score(X_test, y_test)
print(f'Model accuracy: {accuracy*100:.2f}%')

from sklearn.metrics import confusion_matrix, classification_report

# Tahminleri oluşturun
y_pred = model.predict(X_test)

# Confusion matrix'i hesaplayın ve yazdırın
cm = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:')
print(cm)

# Precision, recall ve f1-score'ları hesaplayın ve yazdırın
cr = classification_report(y_test, y_pred)
print('Classification Report:')
print(cr)

import seaborn as sns
import matplotlib.pyplot as plt

# Veri seti üzerinde korelasyon matrisini hesaplayın
correlation_matrix = df.corr()

# Isı haritasını çizin
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Özellikler Arası Korelasyon Isı Haritası")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Lojistik Regresyon modeli tahminlerini alın
y_pred = model.predict(X_test)

# Test setindeki pozitif ve negatif örnekleri ayırın
positive_indices = np.where(y_pred == 1)
negative_indices = np.where(y_pred == 0)

# Veri noktalarını çizin
plt.figure(figsize=(10, 6))
plt.scatter(X_test.iloc[positive_indices]['bmi'], X_test.iloc[positive_indices]['children'], c='g', marker='o', label='Tahmin Edilen 1', alpha=0.5)
plt.scatter(X_test.iloc[negative_indices]['bmi'], X_test.iloc[negative_indices]['children'], c='r', marker='x', label='Tahmin Edilen 0', alpha=0.5)

# Eksen etiketlerini ve başlığı ekleyin
plt.xlabel('BMI')
plt.ylabel('Children')
plt.title('Lojistik Regresyon Modelinin Sınıflandırma Sonuçları')

# Eğitim verisini göster
plt.legend(loc='upper right')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Lojistik regresyon modelinin tahminlerini alın
y_pred = model.predict(X_test)

# Görselleştirme için iki özellik seçin (örneğin 'age' ve 'bmi' özelliklerini kullanalım)
feature1 = 'age'
feature2 = 'bmi'

# X_test verilerini belirtilen iki özelliğe göre alın
x_feature1 = X_test[feature1]
x_feature2 = X_test[feature2]

# True pozitif ve false pozitif verileri ayırın
tp_x = x_feature1[(y_test == 1) & (y_pred == 1)]
tp_y = x_feature2[(y_test == 1) & (y_pred == 1)]

fp_x = x_feature1[(y_test == 0) & (y_pred == 1)]
fp_y = x_feature2[(y_test == 0) & (y_pred == 1)]

tn_x = x_feature1[(y_test == 0) & (y_pred == 0)]
tn_y = x_feature2[(y_test == 0) & (y_pred == 0)]

fn_x = x_feature1[(y_test == 1) & (y_pred == 0)]
fn_y = x_feature2[(y_test == 1) & (y_pred == 0)]

# Veriyi görselleştirin
plt.figure(figsize=(12, 8))
plt.scatter(tp_x, tp_y, marker='o', label='True Positive', color='green')
plt.scatter(fp_x, fp_y, marker='x', label='False Positive', color='red')
plt.scatter(tn_x, tn_y, marker='s', label='True Negative', color='blue')
plt.scatter(fn_x, fn_y, marker='^', label='False Negative', color='orange')

# Eğimli bir karar sınırı çizin
coeff = model.coef_[0]
intercept = model.intercept_

x_boundary = np.linspace(x_feature1.min(), x_feature1.max(), 100)
y_boundary = -(coeff[0] / coeff[1]) * x_boundary - (intercept / coeff[1])

# Eğimli bir sınır çizmek için y_boundary'yi daha karmaşık bir şekilde hesaplayın
# Örneğin, x_boundary ve y_boundary arasındaki ilişkiyi özelleştirebilirsiniz
# Bu örnekte, x_boundary'yi kullanarak eğimli bir sınır hesaplanır
plt.plot(x_boundary, x_boundary * (-coeff[0] / coeff[1]) - (intercept / coeff[1]), '--k', label='Slope Decision Boundary')

plt.xlabel(feature1)
plt.ylabel(feature2)
plt.legend()
plt.title('Lojistik Regresyon Tahminleri ve Eğimli Karar Sınırı')
plt.show()

from sklearn.model_selection import RandomizedSearchCV

# Rastgele seçilecek C değerlerini belirtin
param_dist = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}

# RandomizedSearchCV'yi kullanarak en iyi C değerini bulun
random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, n_iter=6, cv=5)
random_search.fit(X_train, y_train)

# En iyi C değerini alın
best_C = random_search.best_params_['C']

# Modeli en iyi C değeri ile tekrar eğitin
best_model = LogisticRegression(C=best_C)
best_model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Modelin tahminlerini yapın
y_pred = model.predict(X_test)

# Doğruluk (Accuracy) hesapla
accuracy = accuracy_score(y_test, y_pred)

# Hassasiyet (Precision) hesapla
precision = precision_score(y_test, y_pred)

# Duyarlılık (Recall) hesapla
recall = recall_score(y_test, y_pred)

# F1 Puanı (F1 Score) hesapla
f1 = f1_score(y_test, y_pred)

# Sınıf 1 için tahmin olasılıklarını alın
y_prob = model.predict_proba(X_test)[:, 1]

# ROC eğrisi hesapla
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

# AUC hesapla
auc = roc_auc_score(y_test, y_prob)

# Sonuçları görüntüle
print(f'Doğruluk (Accuracy): {accuracy:.2f}')
print(f'Hassasiyet (Precision): {precision:.2f}')
print(f'Duyarlılık (Recall): {recall:.2f}')
print(f'F1 Puanı (F1 Score): {f1:.2f}')
print(f'ROC Eğrisi (AUC): {auc:.2f}')

# ROC eğrisini çizin
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC Eğrisi (AUC = {auc:.2f})')
plt.xlabel('False Positive Oranı (FPR)')
plt.ylabel('True Positive Oranı (TPR)')
plt.title('ROC Eğrisi')
plt.legend()
plt.show()

